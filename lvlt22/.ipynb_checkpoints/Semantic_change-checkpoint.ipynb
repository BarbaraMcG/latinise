{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3i1zJ4BQ1pc"
   },
   "source": [
    "# Semantic change in LatinISE\n",
    "\n",
    "\n",
    "Barbara McGillivray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NyL32TSUqyA"
   },
   "source": [
    "This notebook contains the code for detecting semantic change in the Latin corpus LatinISe using word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pZcI50Z-0-m"
   },
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s04rDpqBSg-y"
   },
   "source": [
    "I install version 4.0 of gensim, which is needed to train the word2vec models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6eiPamUMSivf",
    "outputId": "f393c82f-95ff-4f08-d739-7a743eced552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==4.0 in /Users/barbaramcgillivray/opt/anaconda3/lib/python3.8/site-packages (4.0.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/barbaramcgillivray/opt/anaconda3/lib/python3.8/site-packages (from gensim==4.0) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/barbaramcgillivray/opt/anaconda3/lib/python3.8/site-packages (from gensim==4.0) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/barbaramcgillivray/opt/anaconda3/lib/python3.8/site-packages (from gensim==4.0) (1.6.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: plotly in /Users/barbaramcgillivray/opt/anaconda3/lib/python3.8/site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/barbaramcgillivray/opt/anaconda3/lib/python3.8/site-packages (from plotly) (8.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==4.0\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EnttAvC_7Dg"
   },
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCym1_NBADP6",
    "outputId": "f9fa567a-1127-402a-cc62-02469720b97d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barbaramcgillivray/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "#from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "#from nltk.corpus import stopwords\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "from gensim.models import FastText\n",
    "import gensim\n",
    "from scipy import spatial\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "import spacy\n",
    "import plotly.express as px\n",
    "import re\n",
    "from statistics import mean\n",
    "#from langdetect import detect\n",
    "# to make our plot outputs appear and be stored within the notebook:\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set the parameters of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_or_tokens = \"lemmas\" # this can be \"lemmas\" or \"tokens\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAk1QvSdQyOP"
   },
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4w7hFq6SSUAf"
   },
   "source": [
    "I define the name of the folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sof23JqOSV3C"
   },
   "outputs": [],
   "source": [
    "dir_in = os.path.join(\"/Users\", \"barbaramcgillivray\", \"OneDrive - King's College London\", \"Research\", \"2022\", \"Nexus Linguarum WG4 UC4.2\",  \"LatinISE\")\n",
    "dir_out = os.path.join(dir_in, \"semantic_change_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4O5Io99ySN4W"
   },
   "source": [
    "I define the list of all files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-g1Ld6VxRWik"
   },
   "outputs": [],
   "source": [
    "files = os.listdir(os.path.join(dir_in, \"preprocessed_\"+lemmas_or_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOLUEyREC1XF"
   },
   "source": [
    "How many files are in the folder?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44-n5HICDGRm",
    "outputId": "2a1bbc46-1ad9-424e-eced-690dbfd0cc5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_F4SYzZKBiF8"
   },
   "source": [
    "We only want IntraText files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yc0MF7UGBkEi",
    "outputId": "5a311754-8ef6-472e-a24b-72b75b77f705"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f for f in files[:] if \"IT\" in f]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sx4Y8R_DaHTV"
   },
   "source": [
    "I read the metadata file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1CTee5CAXIZZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>creator</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IT-LAT0001</td>\n",
       "      <td>Vulgata</td>\n",
       "      <td>Hieronymus</td>\n",
       "      <td>382.0</td>\n",
       "      <td>poetry</td>\n",
       "      <td>lat_0382_IT-LAT0001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IT-LAT0537</td>\n",
       "      <td>Ars amatoria</td>\n",
       "      <td>Ovidius Naso, Publius</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>poetry</td>\n",
       "      <td>lat_-009_IT-LAT0537.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>IT-LAT0011</td>\n",
       "      <td>S. Benedicti Regula</td>\n",
       "      <td>Benedictus Nursianus</td>\n",
       "      <td>524.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0524_IT-LAT0011.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IT-LAT0012</td>\n",
       "      <td>In psalmis Davidis expositio</td>\n",
       "      <td>Thomas Aquinas: Sanctus</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_1254_IT-LAT0012.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IT-LAT0014</td>\n",
       "      <td>Adoro te devote</td>\n",
       "      <td>Thomas Aquinas: Sanctus</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>poetry</td>\n",
       "      <td>lat_1254_IT-LAT0014.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>IT-LAT0534_1</td>\n",
       "      <td>De origine et situ Germanorum</td>\n",
       "      <td>Tacitus, Publius (Gaius) Cornelius</td>\n",
       "      <td>116.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0116_IT-LAT0534_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>IT-LAT0534_2</td>\n",
       "      <td>De vita Iulii Agricolae</td>\n",
       "      <td>Tacitus, Publius (Gaius) Cornelius</td>\n",
       "      <td>116.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0116_IT-LAT0534_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>IT-LAT0534_3</td>\n",
       "      <td>Dialogus de oratoribus</td>\n",
       "      <td>Tacitus, Publius (Gaius) Cornelius</td>\n",
       "      <td>116.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0116_IT-LAT0534_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>IT-LAT0534_4</td>\n",
       "      <td>Historiae</td>\n",
       "      <td>Tacitus, Publius (Gaius) Cornelius</td>\n",
       "      <td>116.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0116_IT-LAT0534_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>IT-LAT0202</td>\n",
       "      <td>Institutiones</td>\n",
       "      <td>Iustinianus, Caesar Flavius (Imperator Iustini...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0533_IT-LAT0202.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                          title  \\\n",
       "18      IT-LAT0001                        Vulgata   \n",
       "19      IT-LAT0537                   Ars amatoria   \n",
       "20      IT-LAT0011            S. Benedicti Regula   \n",
       "21      IT-LAT0012   In psalmis Davidis expositio   \n",
       "22      IT-LAT0014                Adoro te devote   \n",
       "...            ...                            ...   \n",
       "683   IT-LAT0534_1  De origine et situ Germanorum   \n",
       "684   IT-LAT0534_2        De vita Iulii Agricolae   \n",
       "685   IT-LAT0534_3         Dialogus de oratoribus   \n",
       "686   IT-LAT0534_4                      Historiae   \n",
       "1265    IT-LAT0202                  Institutiones   \n",
       "\n",
       "                                                creator    date    type  \\\n",
       "18                                           Hieronymus   382.0  poetry   \n",
       "19                                Ovidius Naso, Publius    -9.0  poetry   \n",
       "20                                 Benedictus Nursianus   524.0   prose   \n",
       "21                              Thomas Aquinas: Sanctus  1254.0   prose   \n",
       "22                              Thomas Aquinas: Sanctus  1254.0  poetry   \n",
       "...                                                 ...     ...     ...   \n",
       "683                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "684                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "685                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "686                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "1265  Iustinianus, Caesar Flavius (Imperator Iustini...   533.0   prose   \n",
       "\n",
       "                           file  \n",
       "18      lat_0382_IT-LAT0001.txt  \n",
       "19      lat_-009_IT-LAT0537.txt  \n",
       "20      lat_0524_IT-LAT0011.txt  \n",
       "21      lat_1254_IT-LAT0012.txt  \n",
       "22      lat_1254_IT-LAT0014.txt  \n",
       "...                         ...  \n",
       "683   lat_0116_IT-LAT0534_1.txt  \n",
       "684   lat_0116_IT-LAT0534_2.txt  \n",
       "685   lat_0116_IT-LAT0534_3.txt  \n",
       "686   lat_0116_IT-LAT0534_4.txt  \n",
       "1265    lat_0533_IT-LAT0202.txt  \n",
       "\n",
       "[670 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(os.path.join(dir_in, 'latinise_metadata.csv'), sep = \",\")\n",
    "metadata_df = metadata_df[metadata_df['id'].str.startswith(\"IT\")]\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhZpiNQS4-e-",
    "outputId": "076277dd-fd2a-4d8a-fbd2-cfc27ee88c9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'creator', 'date', 'type', 'file'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of 18       382.0\n",
       "19        -9.0\n",
       "20       524.0\n",
       "21      1254.0\n",
       "22      1254.0\n",
       "         ...  \n",
       "683      116.0\n",
       "684      116.0\n",
       "685      116.0\n",
       "686      116.0\n",
       "1265     533.0\n",
       "Name: date, Length: 670, dtype: float64>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['date'].describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          object\n",
       "title       object\n",
       "creator     object\n",
       "date       float64\n",
       "type        object\n",
       "file        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert date to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               object\n",
       "title            object\n",
       "creator          object\n",
       "date              int64\n",
       "type             object\n",
       "file             object\n",
       "time_interval    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['date'] = metadata_df['date'].astype(int)\n",
    "metadata_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                 id                          title  \\\n",
       "18      IT-LAT0001                        Vulgata   \n",
       "19      IT-LAT0537                   Ars amatoria   \n",
       "20      IT-LAT0011            S. Benedicti Regula   \n",
       "21      IT-LAT0012   In psalmis Davidis expositio   \n",
       "22      IT-LAT0014                Adoro te devote   \n",
       "...            ...                            ...   \n",
       "683   IT-LAT0534_1  De origine et situ Germanorum   \n",
       "684   IT-LAT0534_2        De vita Iulii Agricolae   \n",
       "685   IT-LAT0534_3         Dialogus de oratoribus   \n",
       "686   IT-LAT0534_4                      Historiae   \n",
       "1265    IT-LAT0202                  Institutiones   \n",
       "\n",
       "                                                creator    date    type  \\\n",
       "18                                           Hieronymus   382.0  poetry   \n",
       "19                                Ovidius Naso, Publius    -9.0  poetry   \n",
       "20                                 Benedictus Nursianus   524.0   prose   \n",
       "21                              Thomas Aquinas: Sanctus  1254.0   prose   \n",
       "22                              Thomas Aquinas: Sanctus  1254.0  poetry   \n",
       "...                                                 ...     ...     ...   \n",
       "683                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "684                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "685                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "686                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "1265  Iustinianus, Caesar Flavius (Imperator Iustini...   533.0   prose   \n",
       "\n",
       "                           file  \n",
       "18      lat_0382_IT-LAT0001.txt  \n",
       "19      lat_-009_IT-LAT0537.txt  \n",
       "20      lat_0524_IT-LAT0011.txt  \n",
       "21      lat_1254_IT-LAT0012.txt  \n",
       "22      lat_1254_IT-LAT0014.txt  \n",
       "...                         ...  \n",
       "683   lat_0116_IT-LAT0534_1.txt  \n",
       "684   lat_0116_IT-LAT0534_2.txt  \n",
       "685   lat_0116_IT-LAT0534_3.txt  \n",
       "686   lat_0116_IT-LAT0534_4.txt  \n",
       "1265    lat_0533_IT-LAT0202.txt  \n",
       "\n",
       "[670 rows x 6 columns]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXZIYRhGYgHk"
   },
   "source": [
    "Number of works per year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNyNLraB-imV",
    "outputId": "6fdd9486-2f12-4880-d566-393957afa2ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "-450.0     1\n",
       "-229.0     1\n",
       "-199.0     3\n",
       "-185.0     1\n",
       "-149.0     2\n",
       "          ..\n",
       " 2001.0    4\n",
       " 2002.0    2\n",
       " 2003.0    1\n",
       " 2004.0    1\n",
       " 2005.0    1\n",
       "Name: id, Length: 263, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df0 = metadata_df.groupby(['date']).count()\n",
    "metadata_df0 = metadata_df0['id']\n",
    "metadata_df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "BGdacw4X-9nw",
    "outputId": "faa160f2-1800-41e6-8113-ea200ca0fc29"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = metadata_df0.plot(kind='bar', figsize=(20,16), color=\"indigo\", fontsize=10);\n",
    "#ax.set_alpha(0.5)\n",
    "ax.set_title(\"Number of works per year\", fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RVdJPB8877F"
   },
   "source": [
    "## Split the corpus into subcorpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the first and last year in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAJicX9P2-38",
    "outputId": "02845dc5-194d-4af0-e0a4-704e3848421e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-450.0\n",
      "2005.0\n"
     ]
    }
   ],
   "source": [
    "first_date = min(metadata_df.date)\n",
    "last_date = max(metadata_df.date)\n",
    "print(first_date)\n",
    "print(last_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We stop at 900 CE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = 900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define size of the time intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_interval = 450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_intervals = round((last_date-first_date)/size_interval)\n",
    "n_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUW2Qo0e8rLF"
   },
   "source": [
    "Define the time periods and split the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-450, 0, 450, 900]\n"
     ]
    }
   ],
   "source": [
    "intervals = [None]*(n_intervals+1)\n",
    "for t in range(n_intervals+1):\n",
    "    #print(t)\n",
    "    if t == 0:\n",
    "        intervals[t] = int(first_date)\n",
    "    else:\n",
    "        intervals[t] = int(intervals[t-1]+size_interval)\n",
    "    #print(intervals[t])\n",
    "    \n",
    "print(intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column to the metadata_df for the time interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "range(-450, 0)\n",
      "19      -9.0\n",
      "34     -49.0\n",
      "39     -45.0\n",
      "42     -49.0\n",
      "57     -80.0\n",
      "       ...  \n",
      "635   -149.0\n",
      "638   -107.0\n",
      "642    -37.0\n",
      "643    -37.0\n",
      "649   -229.0\n",
      "Name: date, Length: 77, dtype: float64\n",
      "1\n",
      "range(0, 450)\n",
      "18     382.0\n",
      "23     399.0\n",
      "24     391.0\n",
      "37     158.0\n",
      "38      49.0\n",
      "       ...  \n",
      "682    382.0\n",
      "683    116.0\n",
      "684    116.0\n",
      "685    116.0\n",
      "686    116.0\n",
      "Name: date, Length: 235, dtype: float64\n",
      "2\n",
      "range(450, 900)\n",
      "20      524.0\n",
      "102     800.0\n",
      "104     800.0\n",
      "105     800.0\n",
      "106     800.0\n",
      "        ...  \n",
      "609     598.0\n",
      "634     550.0\n",
      "636     550.0\n",
      "645     450.0\n",
      "1265    533.0\n",
      "Name: date, Length: 73, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>creator</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>file</th>\n",
       "      <th>time_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IT-LAT0001</td>\n",
       "      <td>Vulgata</td>\n",
       "      <td>Hieronymus</td>\n",
       "      <td>382.0</td>\n",
       "      <td>poetry</td>\n",
       "      <td>lat_0382_IT-LAT0001.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IT-LAT0537</td>\n",
       "      <td>Ars amatoria</td>\n",
       "      <td>Ovidius Naso, Publius</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>poetry</td>\n",
       "      <td>lat_-009_IT-LAT0537.txt</td>\n",
       "      <td>-450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>IT-LAT0011</td>\n",
       "      <td>S. Benedicti Regula</td>\n",
       "      <td>Benedictus Nursianus</td>\n",
       "      <td>524.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0524_IT-LAT0011.txt</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IT-LAT0012</td>\n",
       "      <td>In psalmis Davidis expositio</td>\n",
       "      <td>Thomas Aquinas: Sanctus</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_1254_IT-LAT0012.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IT-LAT0014</td>\n",
       "      <td>Adoro te devote</td>\n",
       "      <td>Thomas Aquinas: Sanctus</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>poetry</td>\n",
       "      <td>lat_1254_IT-LAT0014.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>IT-LAT0534_1</td>\n",
       "      <td>De origine et situ Germanorum</td>\n",
       "      <td>Tacitus, Publius (Gaius) Cornelius</td>\n",
       "      <td>116.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0116_IT-LAT0534_1.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>IT-LAT0534_2</td>\n",
       "      <td>De vita Iulii Agricolae</td>\n",
       "      <td>Tacitus, Publius (Gaius) Cornelius</td>\n",
       "      <td>116.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0116_IT-LAT0534_2.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>IT-LAT0534_3</td>\n",
       "      <td>Dialogus de oratoribus</td>\n",
       "      <td>Tacitus, Publius (Gaius) Cornelius</td>\n",
       "      <td>116.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0116_IT-LAT0534_3.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>IT-LAT0534_4</td>\n",
       "      <td>Historiae</td>\n",
       "      <td>Tacitus, Publius (Gaius) Cornelius</td>\n",
       "      <td>116.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0116_IT-LAT0534_4.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>IT-LAT0202</td>\n",
       "      <td>Institutiones</td>\n",
       "      <td>Iustinianus, Caesar Flavius (Imperator Iustini...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>prose</td>\n",
       "      <td>lat_0533_IT-LAT0202.txt</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                          title  \\\n",
       "18      IT-LAT0001                        Vulgata   \n",
       "19      IT-LAT0537                   Ars amatoria   \n",
       "20      IT-LAT0011            S. Benedicti Regula   \n",
       "21      IT-LAT0012   In psalmis Davidis expositio   \n",
       "22      IT-LAT0014                Adoro te devote   \n",
       "...            ...                            ...   \n",
       "683   IT-LAT0534_1  De origine et situ Germanorum   \n",
       "684   IT-LAT0534_2        De vita Iulii Agricolae   \n",
       "685   IT-LAT0534_3         Dialogus de oratoribus   \n",
       "686   IT-LAT0534_4                      Historiae   \n",
       "1265    IT-LAT0202                  Institutiones   \n",
       "\n",
       "                                                creator    date    type  \\\n",
       "18                                           Hieronymus   382.0  poetry   \n",
       "19                                Ovidius Naso, Publius    -9.0  poetry   \n",
       "20                                 Benedictus Nursianus   524.0   prose   \n",
       "21                              Thomas Aquinas: Sanctus  1254.0   prose   \n",
       "22                              Thomas Aquinas: Sanctus  1254.0  poetry   \n",
       "...                                                 ...     ...     ...   \n",
       "683                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "684                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "685                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "686                  Tacitus, Publius (Gaius) Cornelius   116.0   prose   \n",
       "1265  Iustinianus, Caesar Flavius (Imperator Iustini...   533.0   prose   \n",
       "\n",
       "                           file time_interval  \n",
       "18      lat_0382_IT-LAT0001.txt             0  \n",
       "19      lat_-009_IT-LAT0537.txt          -450  \n",
       "20      lat_0524_IT-LAT0011.txt           450  \n",
       "21      lat_1254_IT-LAT0012.txt                \n",
       "22      lat_1254_IT-LAT0014.txt                \n",
       "...                         ...           ...  \n",
       "683   lat_0116_IT-LAT0534_1.txt             0  \n",
       "684   lat_0116_IT-LAT0534_2.txt             0  \n",
       "685   lat_0116_IT-LAT0534_3.txt             0  \n",
       "686   lat_0116_IT-LAT0534_4.txt             0  \n",
       "1265    lat_0533_IT-LAT0202.txt           450  \n",
       "\n",
       "[670 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['time_interval'] = \"\"\n",
    "for t in range(len(intervals)-1):\n",
    "    print(t)\n",
    "    print(range(intervals[t],intervals[t+1]))\n",
    "    metadata_df_t = metadata_df.loc[metadata_df['date'].isin(range(intervals[t],intervals[t+1]))]\n",
    "    print(metadata_df_t.date)\n",
    "    metadata_df.loc[metadata_df['date'].isin(range(intervals[t],intervals[t+1])),'time_interval'] = intervals[t]\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise distribution of time intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_df0 = metadata_df.groupby(['time_interval']).count()\n",
    "metadata_df0 = metadata_df0['id']\n",
    "metadata_df0\n",
    "ax = metadata_df0.plot(kind='bar', figsize=(20,16), color=\"indigo\", fontsize=10);\n",
    "#ax.set_alpha(0.5)\n",
    "ax.set_title(\"Number of works per time interval\", fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to do something about this inbalance. See further down for the \"Historical subcorpus\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training embeddings for the whole corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOVX-oApM02y"
   },
   "source": [
    "Function for printing the vocabulary of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ozTBJwmKM2th"
   },
   "outputs": [],
   "source": [
    "def print_vocab(model, top_n = None):\n",
    "  if model == '':\n",
    "    print(\"Empty model!\")\n",
    "  else:\n",
    "    count = 0\n",
    "    if top_n is not None:\n",
    "      for index, word in enumerate(model.wv.index_to_key):\n",
    "        count+= 1\n",
    "        if count < top_n:\n",
    "          print(f\"word #{index}/{len(model.wv.index_to_key)} is {word}\")\n",
    "    else:\n",
    "      for index, word in enumerate(model.wv.index_to_key):\n",
    "        print(f\"word #{index}/{len(model.wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that converts dates into the standard format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dates(sign, date0):\n",
    "\n",
    "    if sign == \"0\":\n",
    "        if date0 == 0:\n",
    "            final_date = \"+0000\"\n",
    "        elif date0 < 100:\n",
    "            final_date = \"+\" + \"00\" + str(date0)\n",
    "            #print(\"1-final_date\", final_date)\n",
    "        elif date0 < 1000:\n",
    "            final_date = \"+\" + \"0\" + str(date0)\n",
    "            #print(\"2-final_date\", final_date)\n",
    "        else:\n",
    "            final_date = \"+\" + str(date0)\n",
    "            #print(\"3-final_date\", final_date)\n",
    "    else:\n",
    "        if date0 == 0:\n",
    "            final_date = \"+0000\"\n",
    "        elif date0 < 100:\n",
    "            final_date = str(sign) + \"00\" + str(date0)\n",
    "            #print(\"1-final_date\", final_date)\n",
    "        elif date0 < 1000:\n",
    "            final_date = str(sign) + \"0\" + str(date0)\n",
    "            #print(\"2-final_date\", final_date)\n",
    "        else:\n",
    "            final_date = str(sign) + str(date0)\n",
    "            #print(\"3-final_date\", final_date)\n",
    "\n",
    "    if final_date.startswith(\"+\"):\n",
    "        final_date = final_date.replace(\"+\", \"\")\n",
    "    return final_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkUJ4O9kuiYi"
   },
   "source": [
    "#### Stopwords exclusion and further filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I exclude punctuation marks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = ['.', ',', '...', ';', ':', '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a list of lists, containing the tokens of each sentence in the whole corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: lat_0382.0_IT-LAT0001.txt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: \"/Users/barbaramcgillivray/OneDrive - King's College London/Research/2022/Nexus Linguarum WG4 UC4.2/LatinISE/preprocessed_lemmas/lat_0382.0_IT-LAT0001.txt\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5a4a1085b382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lat_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_dates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"preprocessed_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlemmas_or_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msentences_this_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \"/Users/barbaramcgillivray/OneDrive - King's College London/Research/2022/Nexus Linguarum WG4 UC4.2/LatinISE/preprocessed_lemmas/lat_0382.0_IT-LAT0001.txt\""
     ]
    }
   ],
   "source": [
    "corpus = list()\n",
    "files_corpus = metadata_df\n",
    "for index, df_line in files_corpus.iterrows():\n",
    "    #print(\"line:\",df_line['id'], df_line['time_interval'])\n",
    "    sign = \"+\"\n",
    "    #print(df_line['date'])\n",
    "    if df_line['date'] < 0:\n",
    "        sign = \"-\"\n",
    "    #print(\"date:\", convert_dates(sign, abs(df_line['date'])))\n",
    "    file_name = 'lat_'+str(convert_dates(sign, abs(df_line['date'])))+\"_\"+str(df_line['id'])+'.txt'\n",
    "    print(\"3:\",file_name)\n",
    "    file = open(os.path.join(dir_in, \"preprocessed_\"+lemmas_or_tokens, file_name), 'r')\n",
    "    sentences_this_file = list()\n",
    "    while True:\n",
    "        line = file.readline().strip()\n",
    "        if line != \"\":\n",
    "            #sentences_this_file.append(line.split(\" \"))\n",
    "            #sentences_this_file.append([token for token in line.split(\" \") if token not in punctuation])\n",
    "            corpus.append([token for token in line.split(\" \") if token not in punctuation])\n",
    "        # if line is empty end of file is reached\n",
    "        if not line:\n",
    "            break\n",
    "    file.close()\n",
    "corpus.append(sentences_this_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for training FastText models (from Krzysztof Nowak):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext(self, opts=dict()):\n",
    "        \"\"\"\n",
    "        Reads sentences from the corpus. Implements:\n",
    "            https://radimrehurek.com/gensim/models/fasttext.html#gensim.models.fasttext.FastText\n",
    "        Returns\n",
    "        -------\n",
    "        FastText model\n",
    "        \"\"\"\n",
    "        default_opts = dict(vector_size=100, alpha=0.025,\n",
    "                            window=5, min_count=5, epochs=5)\n",
    "        opts_new = default_opts\n",
    "        for opt in opts.keys():\n",
    "            opts_new[opt] = opts[opt]\n",
    "        model = FastText(\n",
    "            vector_size=opts_new[\"vector_size\"],\n",
    "            alpha=opts_new[\"alpha\"],\n",
    "            window=opts_new[\"window\"],\n",
    "            min_count=opts_new[\"min_count\"])\n",
    "        model.build_vocab(corpus_iterable=[sentence for sentence in\n",
    "                                           self.corpus.get_sents()])\n",
    "        total_examples = model.corpus_count\n",
    "        model.train(corpus_iterable=[sentence for sentence\n",
    "                                     in self.corpus.get_sents()],\n",
    "                    total_examples=total_examples,\n",
    "                    epochs=opts_new[\"epochs\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWZPf_3bUe8n"
   },
   "source": [
    "Parameters: \n",
    "\n",
    "`min_count`: the minimum frequency threshold allowed for a word to be included; set to 3 following Ribary & McGillivray (2020) or 5 following Sprugnoli et al. (2019).\n",
    "\n",
    "`vector_size`: the number of dimensions in which we wish to represent our word. This is the size of the word embedding; typically between 100 and 1,000. Set to 100 following Ribary & McGillivray (2020).\n",
    "\n",
    "`window`: The size of the context window determines how many words before and after a given word would be included as context words of the given word.  Typically between 5 and 10. Set to 10 following Sprugnoli et al. (2020).\n",
    "\n",
    "`sg`: – Training algorithm: 1 for skip-gram; otherwise CBOW. Set to 10 following Ribary & McGillivray (2020).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train FastText embeddings and, for full reproducibility, limit the model to a single worker thread (workers=1), to eliminate ordering jitter from OS thread scheduling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(vector_size=100, alpha=0.025, window=1, min_count=50, workers=1, seed=1, hashfxn=hash)\n",
    "model.build_vocab(corpus_iterable=corpus)\n",
    "model.train(corpus_iterable=corpus, total_examples=model.corpus_count, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what words are similar to \"dies\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = FastText(vector_size=100, window=5, min_count=5, workers=1, seed=1,hashfxn=hash)\n",
    "model.build_vocab(corpus_iterable=corpus)\n",
    "model.train(corpus_iterable=corpus, total_examples=model.corpus_count, epochs=5)\n",
    "end = time.time()\n",
    "print(\"It has taken\", round(end - start), \"seconds\")\n",
    "model.wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = FastText(vector_size=100, window=10, min_count=5, workers=1, seed=1,hashfxn=hash)\n",
    "model.build_vocab(corpus_iterable=corpus)\n",
    "model.train(corpus_iterable=corpus, total_examples=model.corpus_count, epochs=5)\n",
    "end = time.time()\n",
    "print(\"It has taken\", round(end - start), \"seconds\")\n",
    "model.wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I experiment with two equivalent ways to train a Fast Text model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(vector_size=100, alpha=0.025, window=1, min_count=50, workers=1, seed=1, hashfxn=hash)\n",
    "model.build_vocab(corpus_iterable=corpus)\n",
    "model.corpus_count\n",
    "model.train(corpus_iterable=corpus, total_examples=model.corpus_count, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = FastText(vector_size=100, alpha=0.025, window=1, min_count=50, workers=1, seed=1, hashfxn=hash, \n",
    "                  sentences=corpus)\n",
    "model2.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.allclose(model.wv['dies'], model2.wv['dies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models has a vocabulary of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.corpus_total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I evaluate different configurations of the parameters for the embeddings against the gold standard set by Sprugnoli et al. (2019) (https://github.com/CIRCSE/Lemma-Embeddings-for-Latin/blob/master/syn-selection-benchmark-Latin.tsv) to find the best configuration of parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gitlab.surrey.ac.uk/mr0048/pydigest/-/blob/master/script/fasttext_003.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE MAY ALSO WANT TO EVALUATE THE TIME-INSENSITIVE EMBEDDINGS (i.e. trained of the full corpus) similarly to Ribary & McGillivray (2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training embeddings for each time interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPcAmEUzA1if"
   },
   "source": [
    "For each time interval, I read the texts from files and create a list of lists, i.e. a list of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that maps a time interval with the list of sentences of texts in that time interval\"\n",
    "time2corpus = dict()\n",
    "\n",
    "# I loop over all time intervals:\n",
    "for t in range(n_intervals+1):\n",
    "    files_corpus_t = metadata_df.loc[metadata_df['time_interval'] == intervals[t]]\n",
    "    #print(\"1:\",files_corpus_t, type(files_corpus_t))\n",
    "    corpus_t = list()\n",
    "    for index, df_line in files_corpus_t.iterrows():\n",
    "        #print(\"line:\",df_line['id'], df_line['time_interval'])\n",
    "        sign = \"+\"\n",
    "        #print(df_line['date'])\n",
    "        if df_line['date'] < 0:\n",
    "            sign = \"-\"\n",
    "        #print(\"date:\", convert_dates(sign, abs(df_line['date'])))\n",
    "        file_name = 'lat_'+str(convert_dates(sign, abs(df_line['date'])))+\"_\"+str(df_line['id'])+'.txt'\n",
    "        #print(\"3:\",file_name)\n",
    "        file = open(os.path.join(dir_in, \"preprocessed_\"+lemmas_or_tokens, file_name), 'r')\n",
    "        sentences_this_file = list()\n",
    "        while True:\n",
    "            line = file.readline().strip()\n",
    "            if line != \"\":\n",
    "                #sentences_this_file.append(line.split(\" \"))\n",
    "                #sentences_this_file.append([token for token in line.split(\" \") if token not in punctuation])\n",
    "                corpus_t.append([token for token in line.split(\" \") if token not in punctuation])\n",
    "            # if line is empty end of file is reached\n",
    "            if not line:\n",
    "                break\n",
    "        file.close()\n",
    "        #corpus_t.append(sentences_this_file)\n",
    "    #corpus_t1\n",
    "    #print(len(corpus_t1[0]))\n",
    "    time2corpus[t] = corpus_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the corpus for the first time interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the second:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2corpus[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the third:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2corpus[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the findings of Sprugnoli et al. (2019) and Ribary & McGillivray (2020), for each time interval I train a fasttext model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the first subcorpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7IjvEPpUfTQ",
    "outputId": "90320e7f-1107-4185-9e7e-c8808d04b65d"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#model = gensim.models.Word2Vec(time2corpus[0], min_count=5, vector_size=100, window = 10, sg = 1)\n",
    "start = time.time()\n",
    "model = FastText(vector_size=100, window=5, min_count=5, workers=1, seed=1,hashfxn=hash)\n",
    "model.build_vocab(corpus_iterable=time2corpus[0])\n",
    "model.train(corpus_iterable=time2corpus[0], total_examples=model.corpus_count, epochs=5)\n",
    "end = time.time()\n",
    "print(\"It has taken\", round(end - start), \"seconds\")\n",
    "model.wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SKoa9tdLH62",
    "outputId": "b3d6c08e-79fa-4832-e899-80933ad395d7"
   },
   "outputs": [],
   "source": [
    "print_vocab(model, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now check the similar words to \"sum\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similar_by_word('sum', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus is small and the fasttext seems to prefer orthographic similarity with smaller min_counts. We're not interested in dies being similar to rabies, but rather dies being similar to annus or mensis. So, we have two options: we may either turn off the subwords or apply high frequency threshold (but we're going to loose low-frequency terms) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try changing the parameters to exclude subwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#model = gensim.models.Word2Vec(time2corpus[0], min_count=5, vector_size=100, window = 10, sg = 1)\n",
    "start = time.time()\n",
    "model = FastText(vector_size=100, window=5, min_count=5, workers=1, seed=1, hashfxn=hash, max_n=0) \n",
    "model.build_vocab(corpus_iterable=time2corpus[0])\n",
    "model.train(corpus_iterable=time2corpus[0], total_examples=model.corpus_count, epochs=5)\n",
    "end = time.time()\n",
    "print(\"It has taken\", round(end - start), \"seconds\")\n",
    "model.wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we could set a higher frequency threshold, but that we would lose low-frequency terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#model = gensim.models.Word2Vec(time2corpus[0], min_count=5, vector_size=100, window = 10, sg = 1)\n",
    "start = time.time()\n",
    "model = FastText(vector_size=100, window=5, min_count=50, workers=1, seed=1, hashfxn=hash, max_n=0) \n",
    "model.build_vocab(corpus_iterable=time2corpus[0])\n",
    "model.train(corpus_iterable=time2corpus[0], total_examples=model.corpus_count, epochs=5)\n",
    "end = time.time()\n",
    "print(\"It has taken\", round(end - start), \"seconds\")\n",
    "model.wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similar_by_word('sum', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now train one model for each time interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time2corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list()\n",
    "start = time.time()\n",
    "for t in range(len(time2corpus)):\n",
    "    if len(time2corpus[t])>0:\n",
    "        print(t)\n",
    "        #model = gensim.models.Word2Vec(time2corpus[0][0], min_count=1, vector_size=300, window = 5, sg = 0)\n",
    "        model = FastText(vector_size=100, window=5, min_count=50, workers=1, seed=1, hashfxn=hash, max_n=0)  # instantiate\n",
    "        model.build_vocab(corpus_iterable=time2corpus[t])\n",
    "        model.train(corpus_iterable=time2corpus[t], total_examples=len(time2corpus[t]), epochs=10)  # train\n",
    "        models.append(model)\n",
    "        #model = fasttext.train_unsupervised(time2corpus[0][0], model='skipgram')\n",
    "end = time.time()\n",
    "print(\"It has taken\", round(end - start), \"seconds, or \", round((end - start)/60), \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check some models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_vocab(models[0], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_vocab(models[1], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[1].wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[2].wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4rjlshWPPkX"
   },
   "source": [
    "##  Embedding space alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using code from https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8, ported from HistWords https://github.com/williamleif/histwords.\n",
    "\n",
    "First, I define a function to find the intersection between the vocabularies of two word2vec models:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_align_gensim(m1, m2, words=None):\n",
    "    \"\"\"\n",
    "    Intersect two gensim word2vec models, m1 and m2.\n",
    "    Only the shared vocabulary between them is kept.\n",
    "    If 'words' is set (as list or set), then the vocabulary is intersected with this list as well.\n",
    "    Indices are re-organized from 0..N in order of descending frequency (=sum of counts from both m1 and m2).\n",
    "    These indices correspond to the new syn0 and syn0norm objects in both gensim models:\n",
    "        -- so that Row 0 of m1.syn0 will be for the same word as Row 0 of m2.syn0\n",
    "        -- you can find the index of any word on the .index2word list: model.index2word.index(word) => 2\n",
    "    The .vocab dictionary is also updated for each model, preserving the count but updating the index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the vocab for each model\n",
    "    vocab_m1 = set(m1.wv.index_to_key)\n",
    "    vocab_m2 = set(m2.wv.index_to_key)\n",
    "\n",
    "    # Find the common vocabulary\n",
    "    common_vocab = vocab_m1 & vocab_m2\n",
    "    if words: common_vocab &= set(words)\n",
    "\n",
    "    # If no alignment necessary because vocab is identical...\n",
    "    if not vocab_m1 - common_vocab and not vocab_m2 - common_vocab:\n",
    "        return (common_vocab, m1,m2)\n",
    "\n",
    "    # Otherwise sort by frequency (summed for both)\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: m1.wv.get_vecattr(w, \"count\") + m2.wv.get_vecattr(w, \"count\"), reverse=True)\n",
    "    # print(len(common_vocab))\n",
    "\n",
    "    # Then for each model...\n",
    "    for m in [m1, m2]:\n",
    "        # Replace old syn0norm array with new one (with common vocab)\n",
    "        indices = [m.wv.key_to_index[w] for w in common_vocab]\n",
    "        old_arr = m.wv.vectors\n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.vectors = new_arr\n",
    "\n",
    "        # Replace old vocab dictionary with new one (with common vocab)\n",
    "        # and old index2word with new one\n",
    "        new_key_to_index = {}\n",
    "        new_index_to_key = []\n",
    "        for new_index, key in enumerate(common_vocab):\n",
    "            new_key_to_index[key] = new_index\n",
    "            new_index_to_key.append(key)\n",
    "        m.wv.key_to_index = new_key_to_index\n",
    "        m.wv.index_to_key = new_index_to_key\n",
    "        \n",
    "        print(len(m.wv.key_to_index), len(m.wv.vectors))\n",
    "        \n",
    "    print(common_vocab)\n",
    "    print(m1)\n",
    "    print(m2)\n",
    "    return (common_vocab, m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I define a function for aligning two spaces with Orthogonal Procrustes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
    "    \"\"\"\n",
    "    Original script: https://gist.github.com/quadrismegistus/09a93e219a6ffc4f216fb85235535faf\n",
    "    Procrustes align two gensim word2vec models (to allow for comparison between same word across models).\n",
    "    Code ported from HistWords <https://github.com/williamleif/histwords> by William Hamilton <wleif@stanford.edu>.\n",
    "        \n",
    "    First, intersect the vocabularies (see `intersection_align_gensim` documentation).\n",
    "    Then do the alignment on the other_embed model.\n",
    "    Replace the other_embed model's syn0 and syn0norm numpy matrices with the aligned version.\n",
    "    Return other_embed.\n",
    "    If `words` is set, intersect the two models' vocabulary with the vocabulary in words (see `intersection_align_gensim` documentation).\n",
    "    \"\"\"\n",
    "\n",
    "    # make sure vocabulary and indices are aligned\n",
    "    common_vocab, in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
    "\n",
    "    # re-filling the normed vectors: the following two lines were added following Japleen Gulati, following amacanovic's comments in the discussion below this page: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
    "\n",
    "    in_base_embed.wv.fill_norms(force=True)\n",
    "    in_other_embed.wv.fill_norms(force=True)\n",
    "    \n",
    "    # get the (normalized) embedding matrices\n",
    "    base_vecs = in_base_embed.wv.get_normed_vectors()\n",
    "    other_vecs = in_other_embed.wv.get_normed_vectors()\n",
    "\n",
    "    # just a matrix dot product with numpy\n",
    "    m = other_vecs.T.dot(base_vecs) \n",
    "    # SVD method from numpy\n",
    "    u, _, v = np.linalg.svd(m)\n",
    "    # another matrix operation\n",
    "    ortho = u.dot(v) \n",
    "    # Replace original array with modified one, i.e. multiplying the embedding matrix by \"ortho\"\n",
    "    other_embed.wv.vectors = (other_embed.wv.vectors).dot(ortho)    \n",
    "    \n",
    "    return other_embed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhvxxR7qQ3Hc"
   },
   "source": [
    "Now I can apply the function to my models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_procrustes_align_gensim(models[2], models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I align all models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oI3tPmmNRXcU",
    "outputId": "c347bdb8-ad34-4133-fecb-f37416bbcf2f"
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "#for t in range(len(models)):\n",
    "#    smart_procrustes_align_gensim(models[t], models[0], words=None)\n",
    "for i in range(0,len(models)-1):\n",
    "    reduce(smart_procrustes_align_gensim, models)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKGD6NZPbxza"
   },
   "source": [
    "Now the models have been aligned and have the same vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(models)):\n",
    "    print(i, len(models[i].wv.index_to_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeSIUxsE8nF7"
   },
   "source": [
    "# Semantic change with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define a function that, given a reference step (either \"first\" or \"last), it returns the time intervals' range to be used to compare models against this reference step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reference_intervals(reference_step, intervals):\n",
    "    \n",
    "    if reference_step == \"first\":\n",
    "        #range_intervals = range(intervals[1], intervals[len(intervals)-1], size_interval)\n",
    "        #range_intervals_index = range(1, len(intervals)-1)\n",
    "        #reference_interval = intervals[0]\n",
    "        reference_interval_index = 0\n",
    "    elif reference_step == \"last\":\n",
    "        #range_intervals = range(intervals[0], intervals[len(intervals)-2], size_interval)\n",
    "        #range_intervals_index = range(0, len(intervals)-2)\n",
    "        #reference_interval = intervals[len(intervals)-1]\n",
    "        reference_interval_index = len(intervals)-2\n",
    "        \n",
    "    #return (range_intervals, range_intervals_index, reference_interval, reference_interval_index)\n",
    "    return reference_interval_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_reference_intervals(\"first\", intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_reference_intervals(\"last\", intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2hcRfD-Bkm0"
   },
   "source": [
    "Let's define a function that calculates the cosine similarity between the embedding of a word in a time interval t and the embedding of the same word in the reference time interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTFtfuLkCUJN"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(word, t, reference_step, models, intervals):\n",
    "    #(range_intervals, range_intervals_index, reference_interval, reference_interval_index)= find_reference_intervals(reference_step)\n",
    "    reference_interval_index = find_reference_intervals(reference_step, intervals)\n",
    "    sc = np.nan\n",
    "    if models[reference_interval_index] == '':\n",
    "        print(\"Model of reference interval is empty!\")\n",
    "    else:\n",
    "        if models[t] != '':\n",
    "            #print(t, word)\n",
    "            sc = 1-spatial.distance.cosine(models[t].wv[word], models[reference_interval_index].wv[word])\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(\"sum\", 2, \"last\", models, intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(\"sum\", 2, \"first\", models, intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtrQJ2QwCaZA"
   },
   "source": [
    "Now I define a function that, given a reference step and a time interval index (starting from 0 for the first model), calculates the semantic similarity for all words in the vocabulary between these two time intervals, and stores this in the dataframe cosine_similarity_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "usdtS7hxCiDc",
    "outputId": "97b22c9e-c219-4750-84df-5cf7988e168b"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_dataframe(reference_step, time_interval_index, models, intervals):\n",
    "    if time_interval_index<0 or time_interval_index>len(models)-1:\n",
    "        print(\"Second argument needs to be between 0 and \", len(models)-1)\n",
    "        \n",
    "    reference_interval_index = find_reference_intervals(reference_step, intervals)\n",
    "    #print(reference_interval_index)\n",
    "    if models[reference_interval_index] != '' and models[time_interval_index] != '':\n",
    "        cosine_similarity_df = pd.DataFrame(([w, \n",
    "            models[reference_interval_index].wv.get_vecattr(w, \"count\"),\n",
    "            models[time_interval_index].wv.get_vecattr(w, \"count\"),\n",
    "            cosine_similarity(w,time_interval_index, reference_step, models, intervals)  \n",
    "            ] for w in models[time_interval_index].wv.index_to_key), \n",
    "        columns = ('Word', \"Frequency_t_reference-\"+str(reference_step), \"Frequency_t\"+str(time_interval_index), \n",
    "        'Cosine_similarity(w_t_reference-'+str(reference_step)+',w_t'+str(time_interval_index)+')'))\n",
    "    else:\n",
    "        print(\"The reference model or the current model are empty!\")\n",
    "        cosine_similarity_df = pd.DataFrame()\n",
    "    return cosine_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_dataframe(\"last\", 0, models, intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_dataframe(\"last\", 1, models, intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7ztnymCHzuk"
   },
   "source": [
    "Visualise the distribution of the semantic similarity scores with a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "fXq_oDpmH21j",
    "outputId": "f7facee9-335c-40a6-d832-98f9bd6266e1"
   },
   "outputs": [],
   "source": [
    "#hist = cosine_similarity_df['Cosine_similarity(w_t0,w_t1)'].hist()\n",
    "# I display the last column of the data frame:\n",
    "hist = cosine_similarity_dataframe(\"last\", 0, models, intervals).iloc[:,-1].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoGHlv8M-lje"
   },
   "source": [
    "Now I can store the full time series of the cosine similarity between the embedding of a word in each time interval and the embedding of that same word in the reference interval (set to \"last\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_step = \"last\"\n",
    "time_series = list()\n",
    "reference_interval_index = find_reference_intervals(reference_step, intervals)\n",
    "time_series_df = pd.DataFrame()\n",
    "#for w in models[reference_interval_index].wv.index_to_key:\n",
    "df = cosine_similarity_dataframe(reference_step, reference_interval_index, models, intervals)\n",
    "time_series_df[df.columns[0]] = df.iloc[:,0]\n",
    "time_series_df[df.columns[1]] = df.iloc[:,1]\n",
    "for i in range(len(models)):\n",
    "    #print(reference_interval_index)\n",
    "    print(\"Interval\", str(intervals[i]), \"with\", str(list(intervals)[reference_interval_index]))\n",
    "    df = cosine_similarity_dataframe(reference_step, i, models, intervals)\n",
    "#    if i == reference_interval_index:\n",
    "#        time_series_df = df\n",
    "#        col_i = \"interval-\"+str(reference_interval_index)\n",
    "#        time_series_df[col_i] = [reference_interval_index for w in models[reference_interval_index].wv.index_to_key]\n",
    "#        col_n = \"neighbours_ref-\"+reference_step\n",
    "#        time_series_df[col_n] = [models[reference_interval_index].wv.similar_by_word(w, 10) for w in models[reference_interval_index].wv.index_to_key]\n",
    "#    else:\n",
    "#        #time_series_df = time_series_df, df.iloc[:,-2:]\n",
    "#        tmp_df = df.iloc[:,-2:]\n",
    "#        #df.iloc[:,-2:].column[0]\n",
    "#        #print(tmp_df.iloc[:,0])\n",
    "#        time_series_df[tmp_df.columns[0]] = tmp_df.iloc[:,0]\n",
    "#        time_series_df[tmp_df.columns[1]] = tmp_df.iloc[:,1]\n",
    "#        col_i = \"interval-\"+str(i)\n",
    "#        time_series_df[col_i] = [i for w in models[reference_interval_index].wv.index_to_key]\n",
    "#        #Finding top 10 nearest neighbours:\n",
    "#        col_n = \"neighbours_t\"+str(i)\n",
    "#        time_series_df[col_n] = [models[i].wv.similar_by_word(w, 10) for w in models[i].wv.index_to_key]\n",
    "    if i != reference_interval_index:\n",
    "        tmp_df = df.iloc[:,-2:]\n",
    "        #df.iloc[:,-2:].column[0]\n",
    "        #print(df.iloc[:,0])\n",
    "        time_series_df[tmp_df.columns[0]] = tmp_df.iloc[:,0]\n",
    "        time_series_df[tmp_df.columns[1]] = tmp_df.iloc[:,1]\n",
    "        col_i = \"interval-\"+str(i)\n",
    "        time_series_df[col_i] = [i for w in models[reference_interval_index].wv.index_to_key]\n",
    "        #Finding top 10 nearest neighbours:\n",
    "        col_n = \"neighbours_t\"+str(i)\n",
    "        time_series_df[col_n] = [models[i].wv.similar_by_word(w, 10) for w in models[i].wv.index_to_key]\n",
    "        #print(time_series_df)\n",
    "    else:\n",
    "        tmp_df = df.iloc[:,-2:]\n",
    "        #df.iloc[:,-2:].column[0]\n",
    "        #print(df.iloc[:,0])\n",
    "        time_series_df[tmp_df.columns[0]] = tmp_df.iloc[:,0]\n",
    "        time_series_df[tmp_df.columns[1]] = tmp_df.iloc[:,1]\n",
    "        col_i = \"interval-\"+str(i)\n",
    "        time_series_df[col_i] = [i for w in models[reference_interval_index].wv.index_to_key]\n",
    "        #Finding top 10 nearest neighbours:\n",
    "        col_n = \"neighbours_t\"+str(i)\n",
    "        time_series_df[col_n] = [models[i].wv.similar_by_word(w, 10) for w in models[i].wv.index_to_key]\n",
    "    \n",
    "time_series_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df.to_csv(os.path.join(dir_out, 'semantic_change_'+str(size_interval)+'_allwords.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df[['interval-0', 'Cosine_similarity(w_t_reference-last,w_t0)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df[['interval-0', 'Cosine_similarity(w_t_reference-last,w_t0)']].describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df[['interval-1', 'Cosine_similarity(w_t_reference-last,w_t1)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df[['Cosine_similarity(w_t_reference-last,w_t0)',\n",
    "                           'Cosine_similarity(w_t_reference-last,w_t1)'\n",
    "               ]].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(time_series_df[['interval-0', 'Cosine_similarity(w_t_reference-last,w_t0)']], \n",
    "        x = 'interval-0', y = 'Cosine_similarity(w_t_reference-last,w_t0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([0,1], \n",
    "            time_series_df[['Cosine_similarity(w_t_reference-last,w_t0)',\n",
    "                           'Cosine_similarity(w_t_reference-last,w_t1)'\n",
    "                           ]].iloc[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I rearrange the dataframe for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_series_df1 = pd.DataFrame(columns=['Time_interval', 'Cosine_sim', 'Word'])\n",
    "time_series_df1 = pd.DataFrame()\n",
    "for index, row in time_series_df.iterrows():\n",
    "    #print(row['interval-0'], row['Cosine_similarity(w_t_reference-last,w_t0)'])\n",
    "    \n",
    "    #temp = pd.DataFrame(\n",
    "    #    {\n",
    "    #        'Time_interval': row['interval-0'],\n",
    "    #        'Cosine_sim': row['Cosine_similarity(w_t_reference-last,w_t0)'],\n",
    "    #        'Word': row['Word']\n",
    "    #    }\n",
    "    #)\n",
    "    #print([row['interval-0'],row['Cosine_similarity(w_t_reference-last,w_t0)'],row['Word']])\n",
    "    #print(pd.DataFrame(\n",
    "    #    [row['interval-0'],row['Cosine_similarity(w_t_reference-last,w_t0)'],row['Word']]))\n",
    "    time_series_df1 = pd.concat([time_series_df1, pd.DataFrame(\n",
    "        [row['interval-0'],row['Cosine_similarity(w_t_reference-last,w_t0)'],row['Word']]).transpose()])\n",
    "    time_series_df1 = pd.concat([time_series_df1, pd.DataFrame(\n",
    "        [row['interval-1'],row['Cosine_similarity(w_t_reference-last,w_t1)'],row['Word']]).transpose()])\n",
    "    #print(time_series_df1)\n",
    "\n",
    "time_series_df1.columns = ['Time_interval', 'Cosine_sim', 'Word']\n",
    "time_series_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print to output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df1.to_csv(os.path.join(dir_out, 'semantic_change1_'+str(size_interval)+'_allwords.csv'), index=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of socio-political terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socio_political_terms = [\"civitas\", \"consilium\", \"consul\", \"dux\", \"gens\", \"hostis\", \"imperator\", \"jus\", \"labor\", \"natio\", \"nobilitas\", \"pontifex\", \"pontificium\", \"populus\", \"potestas\", \"regnum\", \"senatus\", \"sodes\", \"urbs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df_socpol = time_series_df[time_series_df['Word'].isin(socio_political_terms)]\n",
    "time_series_df_socpol.to_csv(os.path.join(dir_out, 'semantic_change_'+str(size_interval)+'_socpolwords.csv'), index=None) \n",
    "time_series_df_socpol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df1_socpol = time_series_df1[time_series_df1['Word'].isin(socio_political_terms)]\n",
    "time_series_df1_socpol.to_csv(os.path.join(dir_out, 'semantic_change1_'+str(size_interval)+'_socpolwords.csv'), index=None) \n",
    "time_series_df1_socpol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df1_socpol.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df1_socpol[\"Time_interval\"] = pd.to_numeric(time_series_df1_socpol[\"Time_interval\"], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df1_socpol[\"Cosine_sim\"] = pd.to_numeric(time_series_df1_socpol[\"Cosine_sim\"], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(socio_political_terms)):\n",
    "    plt.scatter(time_series_df1_socpol[['Time_interval']].iloc[i], \n",
    "            time_series_df1_socpol[['Cosine_sim']].iloc[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#sns.lmplot('Time_interval', 'Cosine_sim', data=time_series_df_socpol, hue='Word', fit_reg=False)\n",
    "sns.lineplot(x='Time_interval', y='Cosine_sim', data=time_series_df1_socpol, hue='Word', legend=\"full\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historiography subcorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I select by time period before 800CE and historical genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_texts = ['LAT0142', 'LAT0241', 'LAT0529', 'LAT0172', 'LAT0123', 'LAT0134', 'LAT0849', 'LAT0148', 'LAT0325', 'LAT0278', 'LAT1040', 'LAT1042', 'LAT0111', 'LAT0054', 'LAT0201', 'LAT0896', 'LAT0959', 'LAT0115', 'LAT0612', 'LAT0776', 'LAT0850', 'LAT0886', 'LAT0121', 'LAT0726', 'LAT0878', 'LAT0768', 'LAT0410', 'LAT0791', 'LAT0196', 'LAT0906', 'LAT0783', 'LAT0909']\n",
    "selected_texts = ['IT-'+f for f in selected_texts]\n",
    "selected_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata_df_sel = pd.read_csv(os.path.join(dir_in, 'Metadata_selected_corpus.csv'), sep = \",\")\n",
    "#metadata_df_sel = metadata_df_sel[(metadata_df_sel['Selected for our study (1 or 0)'] == 1)\n",
    "#                          & (metadata_df_sel['historical texts'] == 1)]\n",
    "metadata_df_sel  = metadata_df[(metadata_df['id'].isin(selected_texts))]\n",
    "metadata_df_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define size of the time intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_interval = 450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intervals = round((last_date-first_date)/size_interval)\n",
    "n_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = [None]*(n_intervals+1)\n",
    "for t in range(n_intervals+1):\n",
    "    #print(t)\n",
    "    if t == 0:\n",
    "        intervals[t] = first_date\n",
    "    else:\n",
    "        intervals[t] = intervals[t-1]+size_interval\n",
    "    #print(intervals[t])\n",
    "    \n",
    "print(intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column to the metadata_df for the time interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df_sel['time_interval'] = \"\"\n",
    "for t in range(len(intervals)-1):\n",
    "    #print(t)\n",
    "    #print(range(intervals[t],intervals[t+1]))\n",
    "    metadata_df_sel_t = metadata_df_sel.loc[metadata_df_sel['date'].isin(range(intervals[t],intervals[t+1]))]\n",
    "    #print(metadata_df_sel_t.date)\n",
    "    metadata_df_sel.loc[metadata_df_sel['date'].isin(range(intervals[t],intervals[t+1])),'time_interval'] = intervals[t]\n",
    "    #print(intervals[t])\n",
    "metadata_df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df_sel.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise distribution of time intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df0_sel = metadata_df_sel.groupby(['time_interval']).count()\n",
    "metadata_df0_sel = metadata_df0_sel['id']\n",
    "metadata_df0_sel\n",
    "ax = metadata_df0_sel.plot(kind='bar', figsize=(20,16), color=\"indigo\", fontsize=10);\n",
    "#ax.set_alpha(0.5)\n",
    "ax.set_title(\"Number of works per time interval\", fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intervals_sel = round((max(metadata_df_sel['time_interval'])-min(metadata_df_sel['time_interval']))/size_interval)\n",
    "n_intervals_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the historical subcorpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training embeddings for the whole subcorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkUJ4O9kuiYi"
   },
   "source": [
    "#### Stopwords exclusion and further filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a list of lists, containing the tokens of each sentence in the whole corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_sel = list()\n",
    "files_corpus_sel = metadata_df_sel\n",
    "for index, df_line in files_corpus_sel.iterrows():\n",
    "    #print(\"line:\",df_line['id'], df_line['time_interval'])\n",
    "    sign = \"+\"\n",
    "    #print(df_line['date'])\n",
    "    if df_line['date'] < 0:\n",
    "        sign = \"-\"\n",
    "    #print(\"date:\", convert_dates(sign, abs(df_line['date'])))\n",
    "    file_name = 'lat_'+str(convert_dates(sign, abs(df_line['date'])))+\"_\"+str(df_line['id'])+'.txt'\n",
    "    #print(\"3:\",file_name)\n",
    "    file = open(os.path.join(dir_in, \"preprocessed_\"+lemmas_or_tokens, file_name), 'r')\n",
    "    sentences_this_file = list()\n",
    "    while True:\n",
    "        line = file.readline().strip()\n",
    "        if line != \"\":\n",
    "            #sentences_this_file.append(line.split(\" \"))\n",
    "            #sentences_this_file.append([token for token in line.split(\" \") if token not in punctuation])\n",
    "            corpus_sel.append([token for token in line.split(\" \") if token not in punctuation])\n",
    "        # if line is empty end of file is reached\n",
    "        if not line:\n",
    "            break\n",
    "    file.close()\n",
    "corpus_sel.append(sentences_this_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df_sel.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train FastText embeddings and, for full reproducibility, limit the model to a single worker thread (workers=1), to eliminate ordering jitter from OS thread scheduling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model_sel = FastText(vector_size=100, alpha=0.025, window=5, min_count=50, workers=1, seed=1, hashfxn=hash, max_n=0, \n",
    "                  sentences=corpus_sel)\n",
    "end = time.time()\n",
    "print(\"It has taken\", round(end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what words are similar to \"dies\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel.wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training embeddings for each time interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPcAmEUzA1if"
   },
   "source": [
    "For each time interval, I read the texts from files and create a list of lists, i.e. a list of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_sel = [None]*(n_intervals_sel+1)\n",
    "for t in range(n_intervals_sel+1):\n",
    "    print(t)\n",
    "    if t == 0:\n",
    "        intervals_sel[t] = min(metadata_df_sel['time_interval'])\n",
    "    else:\n",
    "        intervals_sel[t] = intervals_sel[t-1]+size_interval\n",
    "    print(intervals_sel[t])\n",
    "    \n",
    "print(intervals_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that maps a time interval with the list of sentences of texts in that time interval\"\n",
    "time2corpus_sel = dict()\n",
    "\n",
    "# I loop over all time intervals:\n",
    "for t in range(n_intervals_sel+1):\n",
    "    files_corpus_sel_t = metadata_df_sel.loc[metadata_df_sel['time_interval'] == intervals_sel[t]]\n",
    "    print(\"1:\",t, intervals_sel[t], \"\\n\", files_corpus_sel_t, type(files_corpus_t))\n",
    "    corpus_sel_t = list()\n",
    "    for index, df_line in files_corpus_sel_t.iterrows():\n",
    "        print(\"line:\",df_line['id'], df_line['time_interval'])\n",
    "        sign = \"+\"\n",
    "        #print(df_line['date'])\n",
    "        if df_line['date'] < 0:\n",
    "            sign = \"-\"\n",
    "        #print(\"date:\", convert_dates(sign, abs(df_line['date'])))\n",
    "        file_name = 'lat_'+str(convert_dates(sign, abs(df_line['date'])))+\"_\"+str(df_line['id'])+'.txt'\n",
    "        #print(\"3:\",file_name)\n",
    "        file = open(os.path.join(dir_in, \"preprocessed_\"+lemmas_or_tokens, file_name), 'r')\n",
    "        sentences_this_file = list()\n",
    "        while True:\n",
    "            line = file.readline().strip()\n",
    "            if line != \"\":\n",
    "                #sentences_this_file.append(line.split(\" \"))\n",
    "                #sentences_this_file.append([token for token in line.split(\" \") if token not in punctuation])\n",
    "                corpus_sel_t.append([token for token in line.split(\" \") if token not in punctuation])\n",
    "            # if line is empty end of file is reached\n",
    "            if not line:\n",
    "                break\n",
    "        file.close()\n",
    "        #corpus_t.append(sentences_this_file)\n",
    "    #corpus_t1\n",
    "    #print(len(corpus_t1[0]))\n",
    "    time2corpus_sel[t] = corpus_sel_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2corpus_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the corpus for the first time interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2corpus_sel[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the second:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2corpus_sel[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time2corpus_sel[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the findings of Sprugnoli et al. (2019) and Ribary & McGillivray (2020), for each time interval I train a fasttext model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time2corpus_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sel = list()\n",
    "start = time.time()\n",
    "for t in range(len(time2corpus_sel)):\n",
    "    if len(time2corpus_sel[t])>0:\n",
    "        print(t)\n",
    "        #model = gensim.models.Word2Vec(time2corpus[0][0], min_count=1, vector_size=300, window = 5, sg = 0)\n",
    "        model_sel = FastText(vector_size=100, window=5, min_count=5, workers=1, seed=1,hashfxn=hash, max_n=0)  # instantiate\n",
    "        model_sel.build_vocab(corpus_iterable=time2corpus_sel[t])\n",
    "        model_sel.train(corpus_iterable=time2corpus_sel[t], total_examples=len(time2corpus_sel[t]), epochs=10)  # train\n",
    "        models_sel.append(model_sel)\n",
    "        #model = fasttext.train_unsupervised(time2corpus[0][0], model='skipgram')\n",
    "    else:\n",
    "        models_sel.append(\"\")\n",
    "end = time.time()\n",
    "print(\"It has taken\", round(end - start), \"seconds, or \", round((end - start)/60), \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check some models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_vocab(models_sel[0], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_vocab(models_sel[2], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sel[0].wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sel[1].wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sel[2].wv.similar_by_word('dies', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4rjlshWPPkX"
   },
   "source": [
    "##  Embedding space alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I align all models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oI3tPmmNRXcU",
    "outputId": "c347bdb8-ad34-4133-fecb-f37416bbcf2f"
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "#for t in range(len(models)):\n",
    "#    smart_procrustes_align_gensim(models[t], models[0], words=None)\n",
    "for i in range(0,len(models_sel)-1):\n",
    "    reduce(smart_procrustes_align_gensim, [m for m in models_sel if m != ''])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKGD6NZPbxza"
   },
   "source": [
    "Now the models have been aligned and have the same vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(models_sel)):\n",
    "    if models_sel[i] != '':\n",
    "        print(i, len(models_sel[i].wv.index_to_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeSIUxsE8nF7"
   },
   "source": [
    "# Semantic change with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_interval_index = find_reference_intervals(\"last\", intervals_sel)\n",
    "reference_interval_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sel[2].wv[\"sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_interval_index = find_reference_intervals(\"last\", intervals_sel)\n",
    "reference_interval_index\n",
    "#cosine_similarity(\"sum\", 4, \"last\", models_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(\"sum\", 2, \"first\", models_sel, intervals_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_dataframe(\"last\", 0, models_sel, intervals_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_dataframe(\"first\", 2, models_sel, intervals_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7ztnymCHzuk"
   },
   "source": [
    "Visualise the distribution of the semantic similarity scores with a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "fXq_oDpmH21j",
    "outputId": "f7facee9-335c-40a6-d832-98f9bd6266e1"
   },
   "outputs": [],
   "source": [
    "#hist = cosine_similarity_df['Cosine_similarity(w_t0,w_t1)'].hist()\n",
    "# I display the last column of the data frame:\n",
    "hist = cosine_similarity_dataframe(\"first\", 2, models_sel, intervals_sel).iloc[:,-1].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoGHlv8M-lje"
   },
   "source": [
    "Now I can store the full time series of the cosine similarity between the embedding of a word in each time interval and the embedding of that same word in the reference interval (set to \"last\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_step = \"last\"\n",
    "time_series = list()\n",
    "reference_interval_index = find_reference_intervals(reference_step, intervals)\n",
    "time_series_df_sel = pd.DataFrame()\n",
    "#for w in models[reference_interval_index].wv.index_to_key:\n",
    "df = cosine_similarity_dataframe(reference_step, reference_interval_index, models_sel, intervals_sel)\n",
    "time_series_df_sel[df.columns[0]] = df.iloc[:,0]\n",
    "time_series_df_sel[df.columns[1]] = df.iloc[:,1]\n",
    "for i in range(len(models_sel)):\n",
    "    #print(reference_interval_index)\n",
    "    print(\"Interval\", str(intervals_sel[i]), \"with\", str(list(intervals_sel)[reference_interval_index]))\n",
    "    df = cosine_similarity_dataframe(reference_step, i, models_sel, intervals_sel)\n",
    "#    if i == reference_interval_index:\n",
    "#        time_series_df = df\n",
    "#        col_i = \"interval-\"+str(reference_interval_index)\n",
    "#        time_series_df[col_i] = [reference_interval_index for w in models[reference_interval_index].wv.index_to_key]\n",
    "#        col_n = \"neighbours_ref-\"+reference_step\n",
    "#        time_series_df[col_n] = [models[reference_interval_index].wv.similar_by_word(w, 10) for w in models[reference_interval_index].wv.index_to_key]\n",
    "#    else:\n",
    "#        #time_series_df = time_series_df, df.iloc[:,-2:]\n",
    "#        tmp_df = df.iloc[:,-2:]\n",
    "#        #df.iloc[:,-2:].column[0]\n",
    "#        #print(tmp_df.iloc[:,0])\n",
    "#        time_series_df[tmp_df.columns[0]] = tmp_df.iloc[:,0]\n",
    "#        time_series_df[tmp_df.columns[1]] = tmp_df.iloc[:,1]\n",
    "#        col_i = \"interval-\"+str(i)\n",
    "#        time_series_df[col_i] = [i for w in models[reference_interval_index].wv.index_to_key]\n",
    "#        #Finding top 10 nearest neighbours:\n",
    "#        col_n = \"neighbours_t\"+str(i)\n",
    "#        time_series_df[col_n] = [models[i].wv.similar_by_word(w, 10) for w in models[i].wv.index_to_key]\n",
    "    if i != reference_interval_index:\n",
    "        tmp_df = df.iloc[:,-2:]\n",
    "        #df.iloc[:,-2:].column[0]\n",
    "        #print(df.iloc[:,0])\n",
    "        time_series_df_sel[tmp_df.columns[0]] = tmp_df.iloc[:,0]\n",
    "        time_series_df_sel[tmp_df.columns[1]] = tmp_df.iloc[:,1]\n",
    "        col_i = \"interval-\"+str(i)\n",
    "        time_series_df_sel[col_i] = [i for w in models_sel[reference_interval_index].wv.index_to_key]\n",
    "        #Finding top 10 nearest neighbours:\n",
    "        col_n = \"neighbours_t\"+str(i)\n",
    "        time_series_df_sel[col_n] = [models_sel[i].wv.similar_by_word(w, 10) for w in models_sel[i].wv.index_to_key]\n",
    "        #print(time_series_df)\n",
    "    else:\n",
    "        tmp_df = df.iloc[:,-2:]\n",
    "        #df.iloc[:,-2:].column[0]\n",
    "        #print(df.iloc[:,0])\n",
    "        time_series_df_sel[tmp_df.columns[0]] = tmp_df.iloc[:,0]\n",
    "        time_series_df_sel[tmp_df.columns[1]] = tmp_df.iloc[:,1]\n",
    "        col_i = \"interval-\"+str(i)\n",
    "        time_series_df_sel[col_i] = [i for w in models_sel[reference_interval_index].wv.index_to_key]\n",
    "        #Finding top 10 nearest neighbours:\n",
    "        col_n = \"neighbours_t\"+str(i)\n",
    "        time_series_df_sel[col_n] = [models_sel[i].wv.similar_by_word(w, 10) for w in models_sel[i].wv.index_to_key]\n",
    "    \n",
    "time_series_df_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df_sel.to_csv(os.path.join(dir_out, 'semantic_change_histcorpus_'+str(size_interval)+'_allwords.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(time_series_df_sel[['interval-0', 'Cosine_similarity(w_t_reference-last,w_t0)']], \n",
    "        x = 'interval-0', y = 'Cosine_similarity(w_t_reference-last,w_t0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([0,1], \n",
    "            time_series_df_sel[['Cosine_similarity(w_t_reference-last,w_t0)',\n",
    "                           'Cosine_similarity(w_t_reference-last,w_t1)'\n",
    "                           ]].iloc[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I rearrange the dataframe for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df_sel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_series_df1 = pd.DataFrame(columns=['Time_interval', 'Cosine_sim', 'Word'])\n",
    "time_series_df1_sel = pd.DataFrame()\n",
    "for index, row in time_series_df_sel.iterrows():\n",
    "    #print(row['interval-0'], row['Cosine_similarity(w_t_reference-last,w_t0)'])\n",
    "    \n",
    "    #temp = pd.DataFrame(\n",
    "    #    {\n",
    "    #        'Time_interval': row['interval-0'],\n",
    "    #        'Cosine_sim': row['Cosine_similarity(w_t_reference-last,w_t0)'],\n",
    "    #        'Word': row['Word']\n",
    "    #    }\n",
    "    #)\n",
    "    #print([row['interval-0'],row['Cosine_similarity(w_t_reference-last,w_t0)'],row['Word']])\n",
    "    #print(pd.DataFrame(\n",
    "    #    [row['interval-0'],row['Cosine_similarity(w_t_reference-last,w_t0)'],row['Word']]))\n",
    "    time_series_df1_sel = pd.concat([time_series_df1_sel, pd.DataFrame(\n",
    "        [row['interval-0'],row['Cosine_similarity(w_t_reference-last,w_t0)'],row['Word']]).transpose()])\n",
    "    time_series_df1_sel = pd.concat([time_series_df1_sel, pd.DataFrame(\n",
    "        [row['interval-1'],row['Cosine_similarity(w_t_reference-last,w_t1)'],row['Word']]).transpose()])\n",
    "    #print(time_series_df1_sel)\n",
    "\n",
    "time_series_df1_sel.columns = ['Time_interval', 'Cosine_sim', 'Word']\n",
    "time_series_df1_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print to output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df1_sel.to_csv(os.path.join(dir_out, 'semantic_change1_histcorpus_'+str(size_interval)+'_allwords.csv'), index=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of socio-political terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socio_political_terms = [\"civitas\", \"consilium\", \"consul\", \"dux\", \"gens\", \"hostis\", \"imperator\", \"jus\", \"labor\", \"natio\", \"nobilitas\", \"pontifex\", \"pontificium\", \"populus\", \"potestas\", \"regnum\", \"senatus\", \"sodes\", \"urbs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df_socpol_sel = time_series_df_sel[time_series_df_sel['Word'].isin(socio_political_terms)]\n",
    "time_series_df_socpol_sel.to_csv(os.path.join(dir_out, 'semantic_change_histcorpus_'+str(size_interval)+'_socpolwords.csv'), index=None) \n",
    "time_series_df_socpol_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df1_socpol_sel = time_series_df1_sel[time_series_df1_sel['Word'].isin(socio_political_terms)]\n",
    "time_series_df1_socpol_sel.to_csv(os.path.join(dir_out, 'semantic_change1_histcorpus_'+str(size_interval)+'_socpolwords.csv'), index=None) \n",
    "time_series_df1_socpol_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df1_socpol_sel.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df1_socpol_sel[\"Time_interval\"] = pd.to_numeric(time_series_df1_socpol_sel[\"Time_interval\"], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df1_socpol_sel[\"Cosine_sim\"] = pd.to_numeric(time_series_df1_socpol_sel[\"Cosine_sim\"], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(socio_political_terms)):\n",
    "    plt.scatter(time_series_df1_socpol_sel[['Time_interval']].iloc[i], \n",
    "            time_series_df1_socpol_sel[['Cosine_sim']].iloc[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#sns.lmplot('Time_interval', 'Cosine_sim', data=time_series_df_socpol, hue='Word', fit_reg=False)\n",
    "sns.lineplot(x='Time_interval', y='Cosine_sim', data=time_series_df1_socpol_sel, hue='Word', legend=\"full\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Semantic_change.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
